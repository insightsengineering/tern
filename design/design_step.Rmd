---
title: "STEP fitting and plotting design"
output: html_document
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objective

We want to provide functions to enable Subgroup Treatment Effect Pattern (STEP) graphs for survival and response outcomes.

> A _PlotSTEP_ function computes the treatment effect as a function of a biomarker variable and
plot it at given locations. The function fits multiple Cox or generalized linear (GLM) models at each running window of the biomarker variable then outputs the estimation of treatment effect (hazard
ratio for Cox model, and odds ratio or proportion difference for GLM) along with its
confidence interval at each window center.
> The function fits the treatment effect by a non-parametric function of the biomarker
variable. The method of fitting is also called local polynomial kernel
smoother, using a rectangular kernel. The argument `degree` indicates the degree of
the local polynomial in each window, and the bandwidth `bw` controls the length of
the windows, which also plays the role as the trade-off between bias and variance.
Specifically, decreasing bandwidth will reduce bias but increase variance. If `bw` is
`NULL`, the function treats `bw` to be infinity then the treatment effect is
fitted by a single polynomial function.

## Data

```{r}
library(tern)
library(ggplot2.utils)
library(dplyr)
adtte <- ex_adtte %>%
  filter(
    PARAMCD == "OS"
  ) %>%
  mutate(
    AVAL = day2month(AVAL),
    AVALU = "Months",
    is_event = CNSR == 0,
    ARM_BIN = forcats::fct_collapse(
      ARM,
      CTRL = c("B: Placebo"),
      TRT = c("A: Drug X", "C: Combination")
    ),
    ARM_BIN = droplevels(forcats::fct_relevel(ARM_BIN, "CTRL"))
  ) %>%
  var_relabel(BEP01FL = "BEP",
              BMRKR2 = "Biomarker (Categorical)")
```

## Idea

We can have two sets of functions, a bit similar to the forest plot functions:

1. The first set calculates the required numeric results in a matrix format (we can use a custom S3 class): `fit_survival_step()` and `fit_rsp_step()`.
1. The second is just a single function `g_step()` which takes the result object and creates the ggplot.

The advantage is that we only have a single plotting function and can later add e.g. functions for continuous endpoints easily. Note that here, in contrast to the forest functions, we don't need to create a table as intermediate object, since the main result is a graph without a table. However, this could be added later if required.

## Control function

We use a central control function for the STEP arguments so that we don't need to duplicate this between the outcome specific fitting functions.

```{r, stepcontrol}
library(assertthat)

#' @param biomarker (`numeric` or `NULL`) optional provision of the numeric biomarker variable, which
#'   could be used to infer `bandwidth`, see below.
#' @param use_percentile flag. If `TRUE`, the running windows are created according to
#'   quantiles rather than actual values, i.e. the bandwidth refers to the percentage of data
#'   covered in each window. Suggest `TRUE` if the biomarker variable is not uniformly
#'   distributed.
#' @param bandwidth numeric, indicating the bandwidth of each window. Depending on the argument
#'   `use_percentile`, it can be either the length of actual-value windows or percentage
#'   windows. If `use_percentile = TRUE`, it should be a number between 0 and 1. If
#'   `NULL`, treat the bandwidth to be infinity (see examples below). The default value
#'   is `0.25` for percentage windows and one quarter of the range of the `biomarker`
#'   variable for actual-value windows (requested by `NA`)
#' @param degree nonnegative integer, the degree of polynomial function fitted at each window.
#' @param num_points integer, the number of points at which the hazard ratios are estimated. The
#'   smallest number is 2.
control_step <- function(biomarker = NULL,
                         use_percentile = TRUE,
                         bandwidth,
                         degree = 0L,
                         num_points = 39L) {
  assertthat::assert_that(
    is.null(biomarker) || is.numeric(biomarker),
    assertthat::is.flag(use_percentile),
    is_nonnegative_count(degree),
    assertthat::is.count(num_points) && num_points >= 2
  )
  if (missing(bandwidth)) {
    # Infer bandwidth.
    bandwidth <- if (use_percentile) {
      0.25
    } else if (!is.null(biomarker)) {
      diff(range(biomarker, na.rm = TRUE)) / 4
    } else {
      NULL
    }
  } else {
    # Check bandwidth.
    assertthat::assert_that(
      is.null(bandwidth) ||
        (use_percentile && is_proportion(bandwidth)) ||
        (!use_percentile && assertthat::is.scalar(bandwidth) && bandwidth > 0)
    )
  }
  list(
    biomarker = biomarker,
    use_percentile = use_percentile,
    bandwidth = bandwidth,
    degree = degree,
    num_points = num_points
  )
}

control_step()
```

## Window function

```{r, window}
#' Create a Window-selection Matrix given STEP Control Settings
#'
#' @param x a numerical vector.
#' @param control the `control_step()` list
#'
#' @return A list of two which contains the logical selection matrix `sel`
#'   and interval information matrix `interval`.
#'
window_selection <- function(x,
                             control = control_step()) {

  assertthat::assert_that(
    is.numeric(x),
    is.list(control)
  )

  sel <- matrix(FALSE, length(x), control$num_points)
  out <- matrix(0, control$num_points, 3)
  colnames(out) <- paste("Interval", c("Center", "Lower", "Upper"))
  if (control$use_percentile) {

    # Additional columns
    out <- cbind(out, out)
    colnames(out)[1:3] <- paste("Percentile", c("Center", "Lower", "Upper"))

    # Create windows according to percentile cutoffs
    xs <- seq(0, 1, length = control$num_points + 2)[-1]
    for (i in seq_len(control$num_points)) {
      out[i, 2:3] <- c(max(xs[i] - control$bandwidth, 0), min(xs[i] + control$bandwidth, 1))
      out[i, 5:6] <- quantile(x, out[i, 2:3])
      sel[, i] <- x >= out[i, 5] & x <= out[i, 6]
    }

    # Center is the middle point of percentile window
    out[, 1] <- xs[-control$num_points - 1]
    out[, 4] <- quantile(x, out[, 1])

  } else {

    # Create windows according to cutoffs
    m <- c(min(x), max(x))
    xs <- seq(m[1], m[2], length = control$num_points + 2)[-1]
    for (i in seq_len(control$num_points)) {
      out[i, 2:3] <- c(max(xs[i] - control$bandwidth, m[1]), min(xs[i] + control$bandwidth, m[2]))
      sel[, i] <- x >= out[i, 2] & x <= out[i, 3]
    }

    # Center is the same as the point for predicting
    out[, 1] <- xs[-control$num_points - 1]

  }

  list(sel = sel, interval = out)
}

str(window_selection(x = 1:10), 2)
```

It is used e.g. like this: for each point at which an estimation occurs, the corresponding column in the `sel` matrix that is returned by `window_selection` gives the logical indicator whether that observation is used or not for this particular local estimation. For example, the model functions like `lm()` or `coxph()` have an argument `subset` which takes that vector directly.

```{r, windowuse}
x <- rnorm(100)
y <- rnorm(100)
wd <- window_selection(x, control = control_step(num_points = 5L))
td <- data.frame(x, y)
for (i in seq_len(ncol(wd$sel))) {
  local_fit <- lm(y ~ x, td, subset = wd$sel[, i])
  print(coef(local_fit))
}
```

The `interval` matrix gives details like what is the center of each percentile interval, lower and upper ends as well as the same on the biomarker scale:

```{r, intervalmat}
head(wd$interval)
```

## Formula helper

We will need small helper functions to create the formula. Notice that they are slightly different than the ones used e.g. for the forest plot since we need to have a treatment arm and we might have polynomial terms for the biomarker it can interact with. Also here we have a `biomarker` entry we expect in the variables list since that is interacting with the treatment `arm` and other `covariates` are just additive.

```{r, formsurvhelper}
h_coxph_biomarker_formula <- function(variables, control = control_step()) {
  assertthat::assert_that(
    is.null(variables$covariates) || is.character(variables$covariates),
    is_variables(variables[c("arm", "biomarker", "event", "time")])
  )
  form <- paste0("Surv(", variables$time, ", ", variables$event, ") ~ ", variables$arm)
  if (control$degree > 0) {
    form <- paste0(form, " * poly(", variables$biomarker, ", degree = ", control$degree, ", raw = TRUE)")
  }
  if (!is.null(variables$covariates)) {
    form <- paste(form, "+", paste(variables$covariates, collapse = "+"))
  }
  if (!is.null(variables$strata)) {
    form <- paste0(form, " + strata(", paste0(variables$strata, collapse = ", "), ")")
  }
  as.formula(form)
}

h_coxph_biomarker_formula(list(arm = "TRT", biomarker = "BM", event = "EV", time = "TIME"),
                          control = control_step(degree = 3))
h_coxph_biomarker_formula(list(arm = "TRT", biomarker = "BM", event = "EV", time = "TIME"),
                          control = control_step(degree = 0))
```

Actually we don't really need the biomarker variable name when the degree is zero, but we ask for it anyway as we will have it / makes it easier.

## Understanding the treatment effect estimation for a Cox model with polynomial biomarker term interaction

We tried to understand this from the provided `predict()` method in R from scratch.

```{r, coxpredictions}
set.seed(123)
td <- data.frame(
  time = rgamma(100, 1),
  event = sample(c(1, 0), 100, TRUE),
  x = rnorm(100),
  y = rnorm(100),
  trt = sample(c("A", "B"), 100, TRUE)
)
d <- 1
library(survival)
mod <- coxph(Surv(time, event) ~ trt + poly(x, degree = d, raw = TRUE) + y,
             data = td)

newdata <- td[2, ]
predict(mod, newdata = newdata, type = "terms", se.fit = TRUE)

# we could do this manually too:
nx <- newdata$x
xmat <- poly(nx, degree = d, raw = TRUE) - colMeans(poly(td$x, degree = d, raw = TRUE))
xcoefs <- as.matrix(coef(mod)[2])
termest <- as.numeric(xmat %*% xcoefs)
termest
```

Here we see that we
- don't have an intercept in a Cox regression model. Therefore we also don't need to extend the coefficients artificially with a 1 in the front
- we need to center the predictors by the column means from the sample provided for fitting, before multiplying with the estimated coefficients vector.
- The result is actually not yet a (log) hazard ratio because for that we would need to not just fix one treatment arm value but compare this with the linear predictor term part from the other level.

We can obtain this conveniently with the `predict` method. Let's say we want to estimate the treatment effect at biomarker value `newx = 10`.

```{r, withpred}
newx <- 10
trtlvs <- levels(td$trt)
newdata_trt <- td[1, ] %>%
  dplyr::mutate(x = newx, trt = trtlvs[2])
newdata_ref <- newdata_trt %>%
  dplyr::mutate(trt = trtlvs[1])
fit_trt <- predict(mod, newdata = newdata_trt)
fit_ref <- predict(mod, newdata = newdata_ref)
fit_trt - fit_ref
```

Note that when we use `d = 0` above as the degree, i.e. we just have the arm variable in the model, not the biomarker variable interaction at all, then this reduces to the estimated coefficient for the treatment arm - which is what is needed.

## Treatment effect helper function

Based on the above we can now write a small helper function which gives the estimated treatment effect estimate and corresponding standard error from a biomarker model. This should work for both `coxph` and `glm` models. (to be checked) Note that we need to go back to the more basic model matrix functions to be able to calculate the standard error of the effect estimate. The good thing is that we don't need to filter out other covariates or coefficients because those stay constant between the two rows of the model matrix we are building, therefore are automatically zeroed out in the matrix multiplications.

```{r, linpredhelper}
#' @param data data which was used to fit the model
#' @param model the fitted model object
#' @param variables the variables list
#' @param x value of the biomarker variable at which treatment effect should be estimated at
h_trt_effect_biomarker <- function(data,
                                   model,
                                   variables,
                                   x) {
  assertthat::assert_that(
    is_df_with_variables(data, variables),
    is(model, "coxph") || is(model, "glm"),
    assertthat::is.number(x)
  )
  arm_lvls <- levels(data[[variables$arm]])
  assertthat::assert_that(
    identical(length(arm_lvls), 2L)
  )
  newdata <- data[c(1, 1), ]
  newdata[, variables$biomarker] <- x
  newdata[, variables$arm] <- arm_lvls
  mat <- model.matrix(model, data = newdata)
  mat_diff <- diff(mat)
  est <- mat_diff %*% coef(model)
  var <- mat_diff %*% vcov(model) %*% t(mat_diff)
  se <- sqrt(var)
  c(
    est = est,
    se = se
  )
}

h_trt_effect_biomarker(
  data = td,
  model = mod,
  variables = list(
    time = "time",
    event = "event",
    arm = "trt",
    biomarker = "x",
    covariates = "y"
  ),
  x = newx
)
```

## Stats function

Now we can build the statistics function which fits the model given a logical `subset` vector, the data and the formula.

```{r, statssurv}
#' @param formula the model formula
#' @param data the data set
#' @param variables the variable names list
#' @param x numeric vector of biomarker values where to perform treatment effect estimations.
#' @param subset the logical vector subsetting the data (default is to take all observations)
#' @param control list with details in `control_coxph()` format
s_coxph_subset <- function(formula,
                           data,
                           variables,
                           x,
                           subset = rep(TRUE, nrow(data)),
                           control = control_coxph()) {
  # note: `subset` in `coxph` needs to be an expression referring to `data` variables.
  data$.subset <- subset
  fit <- coxph(
    formula = formula,
    data = data,
    subset = .subset,
    ties = control$ties
  )
  # produce a matrix with one row per `x` and columns `est` and `se`:
  estimates <- t(vapply(
    X = x,
    FUN = h_trt_effect_biomarker,
    FUN.VALUE = c(1, 2),
    data = data,
    model = fit,
    variables = variables
  ))
  q_norm <- qnorm((1 + control$conf_level) / 2)
  cbind(
    n = fit$n,
    events = fit$nevent,
    hr = exp(estimates[, "est"]),
    se = estimates[, "se"],
    ci_lower = exp(estimates[, "est"] - q_norm * estimates[, "se"]),
    ci_upper = exp(estimates[, "est"] + q_norm * estimates[, "se"])
  )
}
```

Let's try this out.

```{r, statsex}
form <- Surv(AVAL, is_event) ~ ARM_BIN * poly(BMRKR1, degree = 2, raw = TRUE)
data <- adtte
stats_res <- s_coxph_subset(
  formula = form,
  data = data,
  variables = list(biomarker = "BMRKR1", arm = "ARM_BIN"),
  x = 1:10
)
```

## Fitting function

Putting all pieces together for the fitting, let's use the survival function as example. We obtain a matrix that includes the interval information as well as the number of patients, events in that interval and the estimation results (treatment arm HR estimate, SE, CI bounds across the biomarker intervals).

```{r, fitsurv}
fit_survival_step <- function(variables,
                              data,
                              control = c(control_step(), control_coxph())) {
  assertthat::assert_that(
    is_df_with_variables(data, variables),
    is.list(control)
  )
  data <- data[!is.na(data[[variables$biomarker]]), ]
  window_sel <- window_selection(x = data[[variables$biomarker]], control = control)
  interval_center <- window_sel$interval[, "Interval Center"]
  form <- h_coxph_biomarker_formula(variables = variables, control = control)
  estimates <- if (is.null(control$bandwidth)) {
    s_coxph_subset(
      formula = form,
      data = data,
      variables = variables,
      x = interval_center,
      control = control
    )
  } else {
    tmp <- mapply(
      FUN = s_coxph_subset,
      x = interval_center,
      subset = as.list(as.data.frame(window_sel$sel)),
      MoreArgs = list(
        formula = form,
        data = data,
        variables = variables,
        control = control
      )
    )
    # maybe we find a more elegant solution than this...
    rownames(tmp) <- c("n", "events", "hr", "se", "ci_lower", "ci_upper")
    t(tmp)
  }
  result <- cbind(window_sel$interval, estimates)
  class(result) <- c("matrix", "step")
  result
}
```

Let's try it out:

```{r, fitsurvexample}
variables <- list(
  arm = "ARM_BIN",
  biomarker = "BMRKR1",
  covariates = c("AGE", "BMRKR2"),
  event = "is_event",
  time = "AVAL"
)

step_matrix <- fit_survival_step(
  variables = variables,
  data = adtte
)
head(step_matrix)
```

## Plot function

Then finally we can plot this. We can in production add some options and generalize, this is just a first prototype.

```{r, graphfun}
g_step <- function(step_matrix) {
  assertthat::assert_that(is(step_matrix, "step"))
  plot_dat <- as.data.frame(step_matrix) %>%
    dplyr::rename(x = "Interval Center") %>%
    dplyr::select(x, hr, ci_lower, ci_upper) %>%
    tidyr::pivot_longer(
      cols = ci_lower:ci_upper,
      names_to = c("type", "bound"),
      names_pattern = "(.*)_(.*)",
      values_to = "y"
    )
  plot_dat <- dplyr::bind_rows(
    dplyr::select(plot_dat, c(x, type, bound, y)),
    dplyr::select(plot_dat, c(x, type, bound, hr)) %>%
      dplyr::rename(y = "hr") %>%
      dplyr::mutate(type = "est", bound = "middle")
  )
  ggplot2::ggplot(plot_dat) +
    ggplot2::geom_hline(yintercept = 1, linetype = 2, color = "gray") +
    ggplot2::geom_point(ggplot2::aes_string(x = "x", y = "y", color = "type", shape = "type")) +
    ggplot2::geom_line(ggplot2::aes_string(x = "x", y = "y", color = "type", linetype = "type", group = "bound"))
}

g_step(step_matrix)
```
